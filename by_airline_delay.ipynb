{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2d3a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "%spark2.pyspark\n",
    "\n",
    "##///노선별 실제와 예상 비행시간 차이\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import date_format\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "df=spark.read.csv(\"hdfs:///user/maria_dev/pro/2008resultfull.csv\", header=True, inferSchema=True)\n",
    "\n",
    "result_df = df.groupBy(\"Origin\",\"Dest\").agg(F.mean(\"ElapsedTimeDelay\").alias(\"ETDM\"))\n",
    "z.show(result_df)\n",
    "\n",
    "##//운항 노선 갯수 출발지별\n",
    "result_df = df.groupBy(\"Origin\").agg(F.count(\"ElapsedTimeDelay\").alias(\"ETDC\")).sort(\"ETDC\")\n",
    "result_df1 = df.groupBy(\"Origin\").agg(F.mean(\"ElapsedTimeDelay\").alias(\"ETDM\")).sort(\"ETDM\")\n",
    "\n",
    "result_df2 = result_df.join(result_df1,result_df1[\"Origin\"]==result_df[\"Origin\"])\n",
    "\n",
    "result_df2 = result_df2.sort(\"ETDC\")\n",
    "z.show(result_df2)\n",
    "\n",
    "%spark2.pyspark\n",
    "##//운항 노선 갯수,딜레이 도착지별\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import date_format\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "df=spark.read.csv(\"hdfs:///user/maria_dev/pro/2008resultfull.csv\", header=True, inferSchema=True)\n",
    "\n",
    "result_df = df.groupBy(\"Dest\").agg(F.count(\"ElapsedTimeDelay\").alias(\"ETDC\")).sort(\"ETDC\")\n",
    "result_df1 = df.groupBy(\"Dest\").agg(F.mean(\"ElapsedTimeDelay\").alias(\"ETDM\")).sort(\"ETDM\")\n",
    "\n",
    "result_df2 = result_df.join(result_df1,result_df1[\"Dest\"]==result_df[\"Dest\"])\n",
    "\n",
    "result_df2 = result_df2.sort(\"ETDC\")\n",
    "\n",
    "\n",
    "\n",
    "z.show(result_df2)\n",
    "\n",
    "#출발지 날씨event별 딜레이 평균시간\n",
    "df_weather = spark.read.csv(\"hdfs:///user/maria_dev/pro/pre2008weather.csv\", header=True, inferSchema=True) \n",
    "\n",
    "df_2008 = spark.read.csv(\"hdfs:///user/maria_dev/pro/2008resultfull.csv\", header=True, inferSchema=True)\n",
    "df_2007 = spark.read.csv(\"hdfs:///user/maria_dev/airline_data/2007.csv\", header=True, inferSchema=True)\n",
    "df_2006 = spark.read.csv(\"hdfs:///user/maria_dev/airline_data/2006.csv\", header=True, inferSchema=True)\n",
    "df_2005 = spark.read.csv(\"hdfs:///user/maria_dev/airline_data/2005.csv\", header=True, inferSchema=True)\n",
    "df_2004 = spark.read.csv(\"hdfs:///user/maria_dev/airline_data/2004.csv\", header=True, inferSchema=True)\n",
    "df_2003 = spark.read.csv(\"hdfs:///user/maria_dev/airline_data/2003.csv\", header=True, inferSchema=True)\n",
    "df_airline = df_2008 df_2003.union(df_2004).union(df_2005).union(df_2006).union(df_2007).union(df_2008)\n",
    "\n",
    "df_airline = df_airline.filter(df_airline[\"Cancelled\"]==0).filter(df_airline[\"Diverted\"]==0)\n",
    "df_airline = df_airline.replace([\"NA\"], [\"0\"], \"CarrierDelay\").replace([\"NA\"], [\"0\"], \"WeatherDelay\")\n",
    "df_airline = df_airline.replace([\"NA\"], [\"0\"], \"NASDelay\").replace([\"NA\"], [\"0\"], \"SecurityDelay\").replace([\"NA\"], [\"0\"], \"LateAircraftDelay\")\n",
    "df_airline = df_airline.withColumn(\"ElapsedTime\", df_airline.ArrTime - df_airline.DepTime)\n",
    "df_airline = df_airline.withColumn(\"CRSElapsedTime\", df_airline.CRSArrTime - df_airline.CRSDepTime)\n",
    "df_airline = df_airline.withColumn(\"ElapsedTimeDelay\", df_airline.CRSElapsedTime - df_airline.ActualElapsedTime)\n",
    "df_airline = df_airline.drop(\"DayOfWeek\", \"FlightNum\", \"Distance\", \"AirTime\", \"TaxiIn\", \"TaxiOut\", \"CancellationCode\")\t\t\t\t\t\t\t\n",
    "\n",
    "airport_dep = df_airline.groupby(\"Origin\").agg(count(\"Year\").alias(\"origin_cnt\")).sort(desc(\"origin_cnt\")).limit(10)\n",
    "airport_arr = df_airline.groupby(\"Dest\").agg(count(\"Year\").alias(\"dest_cnt\")).sort(desc(\"dest_cnt\")).limit(10)\n",
    "airport_list = [row.Origin for row in airport_dep.collect()]\n",
    "df_airline = df_airline.filter(df_airline[\"Origin\"].isin(airport_list) & df_airline[\"Dest\"].isin(airport_list))\n",
    "\n",
    "df_weather = df_weather.select(\"Year\", \"Month\", \"DayOfMonth\", \"AirportCode\", split(df_weather[\"Weather\"],\",\").alias(\"WeatherArray\"))\n",
    "df_weather = df_weather.select(\"Year\", \"Month\", \"DayOfMonth\", \"AirportCode\", explode(\"WeatherArray\").alias(\"Weather\"))\n",
    "\n",
    "df = df_airline.join(df_weather, (df_weather[\"Year\"]==df_airline[\"Year\"]) & (df_weather[\"Month\"]==df_airline[\"Month\"]) \n",
    "    & (df_weather[\"DayOfMonth\"]==df_airline[\"DayOfMonth\"])).filter(df_airline[\"WeatherDelay\"] > 0).filter((df_airline[\"Origin\"]==df_weather[\"AirportCode\"]))\n",
    "result_df = df.groupby(\"Weather\").agg(mean(\"ElapsedTimeDelay\").alias(\"ETDM\"))\n",
    "result_df1 = df.groupby(\"Weather\").agg(count(\"Weather\").alias(\"Count\"))\n",
    "result_df2 = result_df.join(result_df1,result_df1[\"Weather\"]==result_df[\"Weather\"])\n",
    "result_df2 = result_df2.orderBy(desc(\"ETDM\"))\n",
    "z.show(result_df2)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
